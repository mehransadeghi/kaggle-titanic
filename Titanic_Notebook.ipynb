{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85572a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "12a64460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin Embarked  \n",
      "0      0  A/5 21171  7.25   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3324d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "63641781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    \"\"\" Age preprocessing: Adding Age_is_missing col and filling the empty age with an estimate based on Sex and PClass \"\"\"\n",
    "    train_df['Age_Missing'] = train_df['Age'].isna().astype(int)\n",
    "    test_df['Age_Missing'] = test_df['Age'].isna().astype(int)\n",
    "    \n",
    "    global_age = train_df['Age'].median()\n",
    "    group_age = train_df.groupby(['Sex','Pclass'])['Age'].median()\n",
    "    def estimate_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            age = group_age.get((row['Sex'], row['Pclass']), np.nan)\n",
    "            return age if not np.isnan(age) else global_age\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(estimate_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(estimate_age, axis=1)\n",
    "    \n",
    "    \"\"\" Adding a Family_size col that reflects sum of sibsp and parch \"\"\"\n",
    "    \n",
    "    train_df['Family_Size'] = train_df['Parch'] + train_df['SibSp'] + 1\n",
    "    test_df['Family_Size'] = test_df['Parch'] + test_df['SibSp'] + 1\n",
    "    \n",
    "    \"\"\" Fare preprocessing: Filling the empty fare with an estimate based on Sex and PClass \"\"\"\n",
    "    global_fare = train_df['Fare'].median()\n",
    "    group_fare = train_df.groupby(['Sex', 'Pclass'])['Fare'].median()\n",
    "    \n",
    "    def estimate_fare(row):\n",
    "        if pd.isna(row['Fare']):\n",
    "            fare = group_fare.get((row['Sex'], row['Pclass']), np.nan)\n",
    "            return fare if not pd.isna(fare) else global_fare\n",
    "        return row['Fare']\n",
    "    train_df['Fare'] = train_df.apply(estimate_fare, axis=1)\n",
    "    test_df['Fare'] = test_df.apply(estimate_fare, axis=1)\n",
    "    \n",
    "    \"\"\" Change cabin to be the first letter of cabin and also fill with U if it is empty \"\"\"\n",
    "    train_df['Cabin'] = train_df['Cabin'].str[0].fillna('U')\n",
    "    test_df['Cabin'] = test_df['Cabin'].str[0].fillna('U')\n",
    "    \n",
    "    \"\"\" If Embarked is empty, use 'U' \"\"\"\n",
    "    train_df['Embarked'] = train_df['Embarked'].fillna('U')\n",
    "    test_df['Embarked'] = test_df['Embarked'].fillna('U')\n",
    "    \n",
    "    \"\"\" Convert Sex to numerical col (female=1, male=0)\"\"\"\n",
    "    train_df['Sex'] = (train_df['Sex']=='female').astype(int)\n",
    "    test_df['Sex'] = (test_df['Sex']=='female').astype(int)\n",
    "    \n",
    "    \n",
    "    \"\"\" Convert other cat cols to numerical cols \"\"\"\n",
    "    cat_cols = ['Cabin', 'Embarked']\n",
    "    x_train_cat = pd.get_dummies(train_df[cat_cols], prefix=cat_cols, dummy_na=False)\n",
    "    x_test_cat = pd.get_dummies(test_df[cat_cols], prefix=cat_cols, dummy_na=False)\n",
    "    x_test_cat = x_test_cat.reindex(columns=x_train_cat.columns, fill_value=0)\n",
    "    \n",
    "    \"\"\" Standardize some numerical cols \"\"\"\n",
    "    cols_to_standardize = ['Age', 'Fare', 'Family_Size']\n",
    "    mu = train_df[cols_to_standardize].mean()\n",
    "    std = train_df[cols_to_standardize].std(ddof=0)\n",
    "    std = std.replace(0, 1.0)\n",
    "    train_df[cols_to_standardize] = (train_df[cols_to_standardize]-mu)/std\n",
    "    test_df[cols_to_standardize] = (test_df[cols_to_standardize]-mu)/std\n",
    "    \n",
    "    \"\"\" Select numerical cols that we want to use in logistic regression \"\"\"\n",
    "    num_cols = ['Sex', 'Age', 'Age_Missing', 'Family_Size', 'Fare']\n",
    "    x_train_num = train_df[num_cols].astype(float)\n",
    "    x_test_num = test_df[num_cols].astype(float)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    x_train = pd.concat([x_train_num, x_train_cat], axis=1)\n",
    "    x_test = pd.concat([x_test_num, x_test_cat], axis=1)\n",
    "    \n",
    "    return x_train, x_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916081f",
   "metadata": {},
   "source": [
    "## Performing data preprocessing and converting to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3441198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df, x_test_df = preprocess_data()\n",
    "\n",
    "x_train = x_train_df.to_numpy(dtype=np.float64, copy=False)\n",
    "x_test = x_test_df.to_numpy(dtype=np.float64, copy=False)\n",
    "y_train = train_df['Survived'].to_numpy(dtype=np.float64, copy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d913e",
   "metadata": {},
   "source": [
    "## Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2b8427ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def cost_function(X, y, w, b):\n",
    "    z = X @ w + b\n",
    "    return (np.logaddexp(0, z) - y*z).mean()\n",
    "\n",
    "def compute_gradient(X, y, w, b):\n",
    "    m, n = X.shape\n",
    "    z = X @ w + b\n",
    "    f_x = sigmoid(z)\n",
    "    err = f_x - y\n",
    "    d_j_b = err.mean()\n",
    "    d_j_w = (X.T @ err) /m \n",
    "    return d_j_w, d_j_b\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\" TODOs: \"\"\"\n",
    "def cost_function_with_regularization():\n",
    "    pass\n",
    "\n",
    "def gradient_descent_with_regularization():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "74cdbcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 18)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "# arr = np.array([1, 2, 3])\n",
    "\n",
    "# print(sigmoid(arr))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83dbc1af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [110], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\" Define the logistic regression model \"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m f_w_b \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241m+\u001b[39mb)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\" Compute the cost \"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\" Update w and b using gradient descent \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "# Initialize parameters:\n",
    "m, n = x_train.shape\n",
    "w = np.zeros(n)\n",
    "b = 0\n",
    "alpha = 0.001\n",
    "\n",
    "\"\"\" Define the logistic regression model \"\"\"\n",
    "\n",
    "# f_w_b = sigmoid(w.x+b)\n",
    "\n",
    "\"\"\" Compute the cost \"\"\"\n",
    "cost = cost_function(x_train, y_train, w, b)\n",
    "\n",
    "\n",
    "\"\"\" Update w and b using gradient descent \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Get train accuracy \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6eb69f",
   "metadata": {},
   "source": [
    "## SKLearn baseline + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c593c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
