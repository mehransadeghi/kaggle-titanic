{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85572a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12a64460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin Embarked  \n",
      "0      0  A/5 21171  7.25   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63641781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "#     train_df = pd.read_csv('train.csv')\n",
    "#     test_df = pd.read_csv('test.csv')\n",
    "    \"\"\" Age preprocessing: Adding Age_is_missing col and filling the empty age with an estimate based on Sex and PClass \"\"\"\n",
    "    train_df['Age_Missing'] = train_df['Age'].isna().astype(int)\n",
    "    test_df['Age_Missing'] = test_df['Age'].isna().astype(int)\n",
    "    \n",
    "    global_age = train_df['Age'].median()\n",
    "    group_age = train_df.groupby(['Sex','Pclass'])['Age'].median()\n",
    "    def estimate_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            age = group_age.get((row['Sex'], row['Pclass']), np.nan)\n",
    "            return age if not np.isnan(age) else global_age\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(estimate_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(estimate_age, axis=1)\n",
    "    \n",
    "    \"\"\" Adding a Family_size col that reflects sum of sibsp and parch \"\"\"\n",
    "    \n",
    "    train_df['Family_Size'] = train_df['Parch'] + train_df['SibSp'] + 1\n",
    "    test_df['Family_Size'] = test_df['Parch'] + test_df['SibSp'] + 1\n",
    "    \n",
    "    \"\"\" Fare preprocessing: Filling the empty fare with an estimate based on Sex and PClass \"\"\"\n",
    "    global_fare = train_df['Fare'].median()\n",
    "    group_fare = train_df.groupby(['Sex', 'Pclass'])['Fare'].median()\n",
    "    \n",
    "    def estimate_fare(row):\n",
    "        if pd.isna(row['Fare']):\n",
    "            fare = group_fare.get((row['Sex'], row['Pclass']), np.nan)\n",
    "            return fare if not pd.isna(fare) else global_fare\n",
    "        return row['Fare']\n",
    "    train_df['Fare'] = train_df.apply(estimate_fare, axis=1)\n",
    "    test_df['Fare'] = test_df.apply(estimate_fare, axis=1)\n",
    "    \n",
    "    \"\"\" Change cabin to be the first letter of cabin and also fill with U if it is empty \"\"\"\n",
    "    train_df['Cabin'] = train_df['Cabin'].str[0].fillna('U')\n",
    "    test_df['Cabin'] = test_df['Cabin'].str[0].fillna('U')\n",
    "    \n",
    "    \"\"\" If Embarked is empty, use 'U' \"\"\"\n",
    "    train_df['Embarked'] = train_df['Embarked'].fillna('U')\n",
    "    test_df['Embarked'] = test_df['Embarked'].fillna('U')\n",
    "    \n",
    "    \"\"\" Convert Sex to numerical col (female=1, male=0)\"\"\"\n",
    "    train_df['Sex'] = (train_df['Sex']=='female').astype(int)\n",
    "    test_df['Sex'] = (test_df['Sex']=='female').astype(int)\n",
    "    \n",
    "    \n",
    "    \"\"\" Convert other cat cols to numerical cols \"\"\"\n",
    "    cat_cols = ['Cabin', 'Embarked']\n",
    "    x_train_cat = pd.get_dummies(train_df[cat_cols], prefix=cat_cols, dummy_na=False)\n",
    "    x_test_cat = pd.get_dummies(test_df[cat_cols], prefix=cat_cols, dummy_na=False)\n",
    "    x_test_cat = x_test_cat.reindex(columns=x_train_cat.columns, fill_value=0)\n",
    "    \n",
    "    \"\"\" Standardize some numerical cols \"\"\"\n",
    "    cols_to_standardize = ['Age', 'Fare', 'Family_Size']\n",
    "    mu = train_df[cols_to_standardize].mean()\n",
    "    std = train_df[cols_to_standardize].std(ddof=0)\n",
    "    std = std.replace(0, 1.0)\n",
    "    train_df[cols_to_standardize] = (train_df[cols_to_standardize]-mu)/std\n",
    "    test_df[cols_to_standardize] = (test_df[cols_to_standardize]-mu)/std\n",
    "    \n",
    "    \"\"\" Select numerical cols that we want to use in logistic regression \"\"\"\n",
    "    num_cols = ['Sex', 'Age', 'Age_Missing', 'Family_Size', 'Fare']\n",
    "    x_train_num = train_df[num_cols].astype(float)\n",
    "    x_test_num = test_df[num_cols].astype(float)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    x_train = pd.concat([x_train_num, x_train_cat], axis=1)\n",
    "    x_test = pd.concat([x_test_num, x_test_cat], axis=1)\n",
    "    \n",
    "    return x_train, x_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a29ca6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef3d46",
   "metadata": {},
   "source": [
    "## Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55af33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex       Age  Age_Missing  Family_Size      Fare  Cabin_A  Cabin_B  \\\n",
      "0  0.0 -0.534891          0.0     0.059160 -0.502445        0        0   \n",
      "1  1.0  0.668392          0.0     0.059160  0.786845        0        0   \n",
      "2  1.0 -0.234070          0.0    -0.560975 -0.488854        0        0   \n",
      "3  1.0  0.442776          0.0     0.059160  0.420730        0        0   \n",
      "4  0.0  0.442776          0.0    -0.560975 -0.486337        0        0   \n",
      "5  0.0 -0.309276          1.0    -0.560975 -0.478116        0        0   \n",
      "6  0.0  1.871675          0.0    -0.560975  0.395814        0        0   \n",
      "7  0.0 -2.038995          0.0     1.919564 -0.224083        0        0   \n",
      "8  1.0 -0.158865          0.0     0.679295 -0.424256        0        0   \n",
      "9  1.0 -1.136533          0.0     0.059160 -0.042956        0        0   \n",
      "\n",
      "   Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  Cabin_U  Embarked_C  \\\n",
      "0        0        0        0        0        0        0        1           0   \n",
      "1        1        0        0        0        0        0        0           1   \n",
      "2        0        0        0        0        0        0        1           0   \n",
      "3        1        0        0        0        0        0        0           0   \n",
      "4        0        0        0        0        0        0        1           0   \n",
      "5        0        0        0        0        0        0        1           0   \n",
      "6        0        0        1        0        0        0        0           0   \n",
      "7        0        0        0        0        0        0        1           0   \n",
      "8        0        0        0        0        0        0        1           0   \n",
      "9        0        0        0        0        0        0        1           1   \n",
      "\n",
      "   Embarked_Q  Embarked_S  Embarked_U  \n",
      "0           0           1           0  \n",
      "1           0           0           0  \n",
      "2           0           1           0  \n",
      "3           0           1           0  \n",
      "4           0           1           0  \n",
      "5           1           0           0  \n",
      "6           0           1           0  \n",
      "7           0           1           0  \n",
      "8           0           1           0  \n",
      "9           0           0           0  \n"
     ]
    }
   ],
   "source": [
    "print(x_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c75cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.power(np.e, -1*z))\n",
    "\n",
    "def cost_function():\n",
    "    pass\n",
    "\n",
    "def gradient_descent():\n",
    "    pass\n",
    "\n",
    "def logistic_regression():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d95fc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.88079708 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "\n",
    "print(sigmoid(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd08c0",
   "metadata": {},
   "source": [
    "## SKLearn baseline + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469597db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
